{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bd545734",
      "metadata": {
        "id": "bd545734"
      },
      "source": [
        "## Assignment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc408336",
      "metadata": {
        "id": "cc408336"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e8bbf17",
      "metadata": {
        "id": "1e8bbf17"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3c66af",
      "metadata": {
        "id": "ba3c66af"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifiOa7dTX4vx",
        "outputId": "4363e7b0-461a-4c4a-d5d1-09900d075e3e"
      },
      "id": "ifiOa7dTX4vx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n"
      ],
      "metadata": {
        "id": "Vp8zD5L3Yz12"
      },
      "id": "Vp8zD5L3Yz12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "HgsBGk5zjqDd"
      },
      "id": "HgsBGk5zjqDd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n"
      ],
      "metadata": {
        "id": "j6G2eGsijqSm"
      },
      "id": "j6G2eGsijqSm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "l1HaJAEYjqXH"
      },
      "id": "l1HaJAEYjqXH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(r'/content/drive/MyDrive/protein-angle-dataset.csv')"
      ],
      "metadata": {
        "id": "OOsns5M4yMeQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "a3f4af2e-65fa-460c-fa8b-c961cb252f3b"
      },
      "id": "OOsns5M4yMeQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c80f2f40decb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/protein-angle-dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/protein-angle-dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop('position',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "Oa9ZiSc-jqb9"
      },
      "id": "Oa9ZiSc-jqb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74116450",
      "metadata": {
        "id": "74116450"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iNHtOdXKNklV"
      },
      "id": "iNHtOdXKNklV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nytt avsnitt"
      ],
      "metadata": {
        "id": "mOlwvGIbaChY"
      },
      "id": "mOlwvGIbaChY"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kib_uOGTX2--"
      },
      "id": "Kib_uOGTX2--",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb24c9e3",
      "metadata": {
        "id": "cb24c9e3"
      },
      "outputs": [],
      "source": [
        "phi=data['phi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7f3fba",
      "metadata": {
        "id": "1a7f3fba"
      },
      "outputs": [],
      "source": [
        "psi=data['psi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d459e0b8",
      "metadata": {
        "id": "d459e0b8"
      },
      "outputs": [],
      "source": [
        "mean_phi = np.mean(phi)\n",
        "mean_psi = np.mean(psi)\n",
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.scatter(phi, psi,  linewidth=3, edgecolors='w')\n",
        "plt.xlim([-195,195])\n",
        "plt.ylim([-195,195])\n",
        "plt.xlabel('$\\phi$')\n",
        "plt.ylabel('$\\psi$')\n",
        "plt.axhline(y=0,color='k',linestyle='--')\n",
        "plt.axvline(x=0,color='k',linestyle='--')\n",
        "plt.xticks(np.arange(-180, 181, step=60))\n",
        "plt.yticks(np.arange(-180, 181, step=60))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8e8ca9",
      "metadata": {
        "id": "5d8e8ca9"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(phi,psi,bins=30,cmap='Blues')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$\\phi$')\n",
        "plt.ylabel('$\\psi$')\n",
        "plt.xlim([-195,195])\n",
        "plt.ylim([-195,195])\n",
        "plt.xticks(np.arange(-180, 181, step=60))\n",
        "plt.yticks(np.arange(-180, 181, step=60))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uppgift 2: Use the k-means clustering method to cluster the phi and psi angle combinations in the data file.\n",
        "\n"
      ],
      "metadata": {
        "id": "7cnt0FMjcX5k"
      },
      "id": "7cnt0FMjcX5k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "a)Experiment with different values of k. Suggest an appropriate value of k for this task and\n",
        "motivate this choice"
      ],
      "metadata": {
        "id": "Gk96iVMXdIE5"
      },
      "id": "Gk96iVMXdIE5"
    },
    {
      "cell_type": "code",
      "source": [
        "data_array=data.to_numpy()"
      ],
      "metadata": {
        "id": "7W6h2jSHcK8i"
      },
      "id": "7W6h2jSHcK8i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_array)"
      ],
      "metadata": {
        "id": "QRT0wOnSfUpH"
      },
      "id": "QRT0wOnSfUpH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numeric columns (for example 'phi' and 'psi') for clustering\n",
        "data_numeric = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Convert the numeric DataFrame to a NumPy array if not already done\n",
        "data_array = data_numeric.values\n",
        "\n",
        "# Number of clusters\n",
        "k = 2\n",
        "# Create a KMeans instance with k clusters\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "# Fit the model to the data\n",
        "kmeans.fit(data_array)\n",
        "# Centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "# Labels for each point\n",
        "labels = kmeans.labels_\n",
        "# Plot the points with color coding based on labels\n",
        "plt.scatter(data_array[:, 0], data_array[:, 1], c=labels, cmap='viridis')\n",
        "\n",
        "# Plot the centroids\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=100, marker='x')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jd8ID1RmdTU9"
      },
      "id": "jd8ID1RmdTU9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of clusters\n",
        "k = 3\n",
        "# Create a KMeans instance with k clusters\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "# Fit the model to the data\n",
        "kmeans.fit(data_array)\n",
        "# Centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "# Labels for each point\n",
        "labels = kmeans.labels_\n",
        "# Plot the points with color coding based on labels\n",
        "plt.scatter(data_array[:, 0], data_array[:, 1], c=labels, cmap='viridis')\n",
        "\n",
        "# Plot the centroids\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=100, marker='x')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6XabB_y1dTiS"
      },
      "id": "6XabB_y1dTiS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of clusters\n",
        "k = 4\n",
        "# Create a KMeans instance with k clusters\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "# Fit the model to the data\n",
        "kmeans.fit(data_array)\n",
        "# Centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "# Labels for each point\n",
        "labels = kmeans.labels_\n",
        "# Plot the points with color coding based on labels\n",
        "plt.scatter(data_array[:, 0], data_array[:, 1], c=labels, cmap='viridis')\n",
        "\n",
        "# Plot the centroids\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=100, marker='x')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4Akm_hludTtU"
      },
      "id": "4Akm_hludTtU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data' is your dataset\n",
        "inertia = []\n",
        "range_of_clusters = range(1, 11)  # Example: checking for 1 to 10 clusters\n",
        "\n",
        "for k in range_of_clusters:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(data_array)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range_of_clusters, inertia, marker='o')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.xlabel('Number of clusters, k')\n",
        "plt.ylabel('Inertia')\n",
        "plt.xticks(range_of_clusters)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "1xaBWENGdT3Y"
      },
      "id": "1xaBWENGdT3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_array)\n",
        "eps_value = 0.15  # Assuming you've already chosen an eps value based on the elbow method\n",
        "min_samples_values = range(2,9 )  # Example range, adjust as needed\n",
        "silhouette_scores = []\n",
        "\n",
        "for min_samples in min_samples_values:\n",
        "    dbscan = DBSCAN(eps=eps_value, min_samples=min_samples).fit(data_scaled)\n",
        "    labels = dbscan.labels_\n",
        "\n",
        "    # Silhouette score is only defined if number of labels is 2 <= n_labels <= n_samples - 1\n",
        "    if len(set(labels)) > 1 and len(set(labels)) < len(data_scaled):\n",
        "        score = silhouette_score(data_scaled, labels)\n",
        "        silhouette_scores.append(score)\n",
        "    else:\n",
        "        silhouette_scores.append(-1)  # Invalid or trivial clustering\n",
        "\n",
        "# Plot silhouette scores\n",
        "plt.plot(min_samples_values, silhouette_scores, marker='o')\n",
        "plt.xlabel('min_samples')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for different min_samples')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TPdiO1UwdUDh"
      },
      "id": "TPdiO1UwdUDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9cc2edd",
      "metadata": {
        "id": "e9cc2edd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "X =data_array\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=0.15, min_samples=5).fit(X_scaled)\n",
        "\n",
        "# Extract labels\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Scatter plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='hot', marker='o')\n",
        "plt.title('DBSCAN Clustering')\n",
        "plt.xlabel('phi')\n",
        "plt.ylabel('psi')\n",
        "\n",
        "# 2D histogram\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist2d(X[:, 0], X[:, 1], bins=30, cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('2D Histogram of phi and psi')\n",
        "plt.xlabel('phi')\n",
        "plt.ylabel('psi')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your dataset\n",
        "# data = pd.read_csv('path_to_your_data.csv')\n",
        "\n",
        "# Assuming 'phi' and 'psi' are the columns of interest\n",
        "# X = data[['phi', 'psi']].values\n",
        "\n",
        "# It's important to standardize the data for DBSCAN\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Use the NearestNeighbors class to find the nearest neighbors\n",
        "nearest_neighbors = NearestNeighbors(n_neighbors=5)\n",
        "nearest_neighbors.fit(data_scaled)\n",
        "\n",
        "# Find the distance to the nearest n points for each point\n",
        "distances, indices = nearest_neighbors.kneighbors(data_scaled)\n",
        "\n",
        "# Sort the distances\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:, 4]  # Taking the distance to the 5th nearest neighbor\n",
        "\n",
        "# Plot the k-distance graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(distances)\n",
        "plt.title('K-distance Graph')\n",
        "plt.xlabel('Points sorted by distance to 5th nearest neighbor')\n",
        "plt.ylabel('5th nearest neighbor distance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KKG7ICfhchuY"
      },
      "id": "KKG7ICfhchuY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "outlier_indices = np.where(labels == -1)[0]\n",
        "\n",
        "# Filter the DataFrame to include only the outliers\n",
        "outliers_data = data.iloc[outlier_indices]\n",
        "\n",
        "# Count the frequency of each residue type among the outliers\n",
        "# Make sure to replace 'residue_name' with the actual name of your column\n",
        "outlier_residue_counts = outliers_data['residue name'].value_counts()\n",
        "\n",
        "# Check if we have any outliers to plot\n",
        "if not outlier_residue_counts.empty:\n",
        "    # Plot the bar chart\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    outlier_residue_counts.plot(kind='bar')\n",
        "    plt.title('Frequency of Amino Acid Residue Types Among Outliers')\n",
        "    plt.xlabel('Residue Type')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No outliers were detected.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-QAa0X3zcilU"
      },
      "id": "-QAa0X3zcilU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdYAlweMG8VV"
      },
      "id": "KdYAlweMG8VV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task4: The data file can be stratified by amino acid residue type. Use DBSCAN to cluster the data that have residue type PRO. Investigate how the clusters found for amino acid residues of type PRO differ from the general clusters (i.e., the clusters that you get from DBSCAN with mixed residue types in question 3). Note: the parameters might have to be adjusted from those used in question 3."
      ],
      "metadata": {
        "id": "l-zgdS69G9MR"
      },
      "id": "l-zgdS69G9MR"
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(r'/content/drive/MyDrive/protein-angle-dataset.csv')\n",
        "residue = data [data['residue name'] == 'PRO' ]\n",
        "residue.drop('position',inplace=True,axis=1)\n",
        "residue_numeric = residue.select_dtypes(include=[np.number])\n",
        "\n",
        "# Convert the numeric DataFrame to a NumPy array if not already done\n",
        "residue_array = residue_numeric.values\n",
        "print(residue)\n",
        "X =residue_array\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=1, min_samples=3).fit(X_scaled)\n",
        "\n",
        "# Extract labels\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Scatter plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o')\n",
        "plt.title('DBSCAN Clustering')\n",
        "plt.xlabel('phi')\n",
        "plt.ylabel('psi')\n",
        "\n",
        "# 2D histogram\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist2d(X[:, 0], X[:, 1], bins=30, cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('2D Histogram of phi and psi')\n",
        "plt.xlabel('phi')\n",
        "plt.ylabel('psi')"
      ],
      "metadata": {
        "id": "cvubTaVmpvhf"
      },
      "id": "cvubTaVmpvhf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "# data = pd.read_csv('path_to_your_data.csv')\n",
        "\n",
        "# Assuming 'phi' and 'psi' are the columns of interest\n",
        "# X = data[['phi', 'psi']].values\n",
        "\n",
        "# It's important to standardize the data for DBSCAN\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Use the NearestNeighbors class to find the nearest neighbors\n",
        "nearest_neighbors = NearestNeighbors(n_neighbors=5)\n",
        "nearest_neighbors.fit(X_scaled)\n",
        "\n",
        "# Find the distance to the nearest n points for each point\n",
        "distances, indices = nearest_neighbors.kneighbors(X_scaled)\n",
        "\n",
        "# Sort the distances\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:, 4]  # Taking the distance to the 5th nearest neighbor\n",
        "\n",
        "# Plot the k-distance graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(distances)\n",
        "plt.title('K-distance Graph')\n",
        "plt.xlabel('Points sorted by distance to 5th nearest neighbor')\n",
        "plt.ylabel('5th nearest neighbor distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Ve-6h-hJzDt"
      },
      "id": "6Ve-6h-hJzDt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the data\n",
        "data = pd.read_csv(r'/content/drive/MyDrive/protein-angle-dataset.csv')\n",
        "residue = data[data['residue name'] == 'PRO']\n",
        "residue.drop(['position'], inplace=True, axis=1)\n",
        "residue_numeric = residue.select_dtypes(include=[np.number])\n",
        "residue_array = residue_numeric.values\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(residue_array)\n",
        "\n",
        "# Define ranges for eps and min_samples\n",
        "eps_values = [0.5, 0.7, 1.0]  # Example eps values\n",
        "min_samples_range = range(2, 9)  # Range of min_samples values\n",
        "\n",
        "# Create subplots for each eps value\n",
        "fig, axes = plt.subplots(1, len(eps_values), figsize=(15, 5), sharey=True)\n",
        "\n",
        "for i, eps in enumerate(eps_values):\n",
        "    silhouette_scores = []\n",
        "    for min_samples in min_samples_range:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(X_scaled)\n",
        "        labels = dbscan.labels_\n",
        "\n",
        "        # Compute silhouette score only if valid\n",
        "        if len(set(labels)) > 1 and len(set(labels)) < len(X_scaled):\n",
        "            score = silhouette_score(X_scaled, labels)\n",
        "            silhouette_scores.append(score)\n",
        "        else:\n",
        "            silhouette_scores.append(-1)  # Invalid or trivial clustering\n",
        "\n",
        "    # Plot silhouette scores for this eps value\n",
        "    ax = axes[i]\n",
        "    ax.plot(min_samples_range, silhouette_scores, marker='o')\n",
        "    ax.set_title(f'eps={eps}')\n",
        "    ax.set_xlabel('min_samples')\n",
        "    if i == 0:\n",
        "        ax.set_ylabel('Silhouette Score')\n",
        "\n",
        "plt.suptitle('Silhouette Scores for Different eps Values')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WHug10DRPfQv"
      },
      "id": "WHug10DRPfQv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(r'/content/drive/MyDrive/protein-angle-dataset.csv')\n",
        "residue = data[data['residue name'] == 'PRO']\n",
        "residue.drop(['position'], inplace=True, axis=1)\n",
        "residue_numeric = residue.select_dtypes(include=[np.number])\n",
        "\n",
        "# Convert to NumPy array\n",
        "X = residue_numeric.values\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Define different values for eps and min_samples\n",
        "eps_values = [0.5, 1, 1.5]  # Example values\n",
        "min_samples_values = [6, 7, 3]  # Example values\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(len(eps_values), len(min_samples_values), figsize=(15, 15))\n",
        "\n",
        "for i, eps in enumerate(eps_values):\n",
        "    for j, min_samples in enumerate(min_samples_values):\n",
        "        # Perform DBSCAN\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(X_scaled)\n",
        "        labels = dbscan.labels_\n",
        "\n",
        "        # Select the subplot\n",
        "        ax = axes[i, j]\n",
        "\n",
        "        # Scatter plot\n",
        "        ax.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o')\n",
        "        ax.set_title(f'DBSCAN: eps={eps}, min_samples={min_samples}')\n",
        "        ax.set_xlabel('phi')\n",
        "        ax.set_ylabel('psi')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vSez62Tqexul"
      },
      "id": "vSez62Tqexul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and a set of subplots with 1 row and 2 columns\n",
        "  # figsize can be adjusted as needed\n",
        "\n",
        "# Now, you can plot on each subplot by indexing into the 'axes' array.\n",
        "\n",
        "# Plot on the first subplot (index 0)\n",
        "X =data_array\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=0.15, min_samples=5).fit(X_scaled)\n",
        "\n",
        "# Extract labels\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Scatter plot\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='hot', marker='o')\n",
        "plt.title('DBSCAN Clustering')\n",
        "plt.xlabel('phi')\n",
        "plt.ylabel('psi')\n",
        "\n",
        "\n",
        "\n",
        "data=pd.read_csv(r'/content/drive/MyDrive/protein-angle-dataset.csv')\n",
        "residue = data [data['residue name'] == 'PRO' ]\n",
        "residue.drop('position',inplace=True,axis=1)\n",
        "residue_numeric = residue.select_dtypes(include=[np.number])\n",
        "\n",
        "# Convert the numeric DataFrame to a NumPy array if not already done\n",
        "residue_array = residue_numeric.values\n",
        "P =residue_array\n",
        "P_scaled = StandardScaler().fit_transform(P)\n",
        "\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=1, min_samples=3).fit(P_scaled)\n",
        "\n",
        "# Extract labels\n",
        "labels = dbscan.labels_\n",
        "\n",
        "\n",
        "\n",
        "# Scatter plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(P[:, 0], P[:, 1], c=labels, cmap='viridis', marker='o')\n",
        "plt.title('DBSCAN Clustering')\n",
        "plt.xlabel('phi')\n",
        "plt.ylabel('psi')\n",
        "\n",
        "\n",
        "# Ensure that the plots are not overlapping\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the figure with subplots\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TonZ04MNe9AO"
      },
      "id": "TonZ04MNe9AO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQHfnWh0wOie"
      },
      "id": "PQHfnWh0wOie",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}